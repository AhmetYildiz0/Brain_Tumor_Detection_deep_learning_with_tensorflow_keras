# -*- coding: utf-8 -*-
"""Brain_Tumor_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hkj4UPOKCgGjUnTLxgKU7XOUhLY5rprH
"""

# Commented out IPython magic to ensure Python compatibility.
# this part for colab. if you work local then skip this part
from google.colab import drive
drive.mount('/content/drive/')



import os
import numpy as np
from tqdm import tqdm
import cv2
import matplotlib.pyplot as plt
# %matplotlib inline

os.chdir("/content/drive/MyDrive/yapay_zeka_video/S-004-Brain-Tumor-Detection/")

from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras.layers import *

# Dataset from https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection
data=[]
# yes=1,no=0
label=[]

files=os.listdir("brain_tumor_dataset/no/")
print("No :")
for file_data in tqdm(files):
  data.append(cv2.imread("brain_tumor_dataset/no/"+file_data,cv2.COLOR_BGR2GRAY))
  label.append([0])

files=os.listdir("brain_tumor_dataset/yes/")
print("Yes :")
for file_data in tqdm(files):
  data.append(cv2.imread("brain_tumor_dataset/yes/"+file_data,cv2.COLOR_BGR2GRAY))
  label.append([1])

# preprossesing data
temp_data,temp_label=[],[]
img_size=224
# resize and normalize
for x in range(len(data)):
  data[x]=cv2.resize(data[x], (img_size,img_size), interpolation = cv2.INTER_AREA)
  data[x]=cv2.normalize(data[x], None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)
  temp2=np.array(data[x])
  if temp2.shape==(img_size,img_size,3):
    temp_data.append(temp2)
    temp_label.append(label[x])


label=np.array(temp_label)
data=np.array(temp_data)
del temp_data,temp_label

# split data
x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)
del data,label

print("x_train :",x_train.shape)
print("y_train :",y_train.shape)
print("x_test  :",x_test.shape)
print("y_test :",y_test.shape)

# show random image
img_idx=np.random.choice(np.arange(0,len(x_train)),20)

plt.figure(figsize=(15,7))

for x in range(len(img_idx)):
  plt.subplot(4,5,x+1)
  plt.imshow(x_train[img_idx[x]])

plt.tight_layout()
plt.show()

# create model
tf.keras.backend.clear_session()
model=tf.keras.models.Sequential()
# x_train.shape = (149, 224, 224, 3)
model.add(Conv2D(input_shape=(x_train.shape[-3],x_train.shape[-2],x_train.shape[-1]),filters=8,kernel_size=(3,3),padding="same", activation="relu"))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))

model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(units=128,activation="relu"))
model.add(Dropout(0.5))
model.add(Dense(units=128,activation="relu"))
model.add(Dropout(0.5))
model.add(Dense(units=y_train.shape[-1], activation="sigmoid"))

model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), 
              loss=tf.losses.BinaryCrossentropy(),
              metrics=['accuracy'])

model.summary()

# train the model

history=model.fit(x_train,y_train,batch_size=8,epochs=30,validation_data=(x_test,y_test))

# evaluate the model

train_result=model.evaluate(x_train,y_train,verbose=0)
test_result=model.evaluate(x_test,y_test,verbose=0)

print("<=======Result=======>")
print("Trian Loss     : ",round(train_result[0],ndigits=3))
print("Trian Accuracy :%",round(train_result[1]*100,ndigits=3))
print()
print("Test Loss      : ",round(test_result[0],ndigits=3))
print("Test Accuracy  :%",round(test_result[1]*100,ndigits=3))

# save the model
model.save("Brain_Tumor_Detection.h5")